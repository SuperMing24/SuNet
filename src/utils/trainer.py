"""è®­ç»ƒå™¨ - åè°ƒæ‰€æœ‰ç»„ä»¶"""
import os
import time
from abc import abstractmethod
from typing import Dict, Any, Optional

import torch
import torch.optim as optim
from torch.optim.lr_scheduler import ReduceLROnPlateau

class ModelManager:
    """æ¨¡å‹ç®¡ç†å™¨ - ä¸“æ³¨æ¨¡å‹ä¿å­˜åŠ è½½"""

    def __init__(self, save_dir: str = "checkpoints"):
        self.save_dir = save_dir
        os.makedirs(save_dir, exist_ok=True)

    def save(self, model: torch.nn.Module, optimizer: optim.Optimizer,
             epoch: int, filename: str, **kwargs):
        """ä¿å­˜æ¨¡å‹æ£€æŸ¥ç‚¹"""
        state = {
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'epoch': epoch,
            **kwargs
        }
        torch.save(state, os.path.join(self.save_dir, filename))

    def load(self, model: torch.nn.Module, optimizer: optim.Optimizer,
             filepath: str) -> Optional[Dict[str, Any]]:
        """åŠ è½½æ¨¡å‹æ£€æŸ¥ç‚¹ - å¥å£®å®ç°"""
        filepath = os.path.join(self.save_dir, filepath)
        if not os.path.exists(filepath):
            print(f"æ£€æŸ¥ç‚¹ä¸å­˜åœ¨: '{filepath}'")
            return None

        try:
            # è‡ªåŠ¨è®¾å¤‡æ˜ å°„
            map_location = 'cuda' if torch.cuda.is_available() else 'cpu'
            state = torch.load(filepath, map_location=map_location)

            model.load_state_dict(state['model_state_dict'])
            optimizer.load_state_dict(state['optimizer_state_dict'])

            print(f"æˆåŠŸåŠ è½½æ£€æŸ¥ç‚¹ (epoch {state.get('epoch', 'unknown')})")
            return {'epoch': state.get('epoch', 0), **state}
        except Exception as e:
            print(f"åŠ è½½æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
            return None

class Trainer:
    prompt = '(trainer) '

    def __init__(self, config: Dict[str, Any]):
        super().__init__()
        self.config = config
        self.device = config.get('device', torch.device('cuda' if torch.cuda.is_available() else 'cpu'))

        # åˆå§‹åŒ–æ¨¡å‹
        self.model = config['model'].to(self.device)
        self.optimizer = optim.Adam(self.model.parameters(), lr=config.get('lr', 1e-4))
        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        self.scheduler = ReduceLROnPlateau(self.optimizer, 'min', patience=5)

        # æŸå¤±å‡½æ•° - è¡€ç®¡åˆ†å‰²é»˜è®¤ä½¿ç”¨clDice
        self.loss_fn = config.get('loss_fn')
        # è¯„ä¼°ç³»ç»Ÿ
        self.metric_evaluator = config.get('metric_evaluator')

        # æ—¥å¿—ç³»ç»Ÿ
        self.loggers = config('loggers')
        self.model_manager = ModelManager(config('model_dir'))

        # è®­ç»ƒçŠ¶æ€
        self.current_epoch = 1
        self.best_metric = float('inf')  # é»˜è®¤ç›‘æ§æŸå¤±
        self.train_loader = None
        self.val_loader = None

        # æ—©åœæœºåˆ¶
        self.patience = config.get('patience', 10)
        self.early_stop_counter = 0

        # ä»æ£€æŸ¥ç‚¹æ¢å¤
        if 'checkpoint' in config:
            self._load_checkpoint(config['checkpoint'])

        self.trainning = False

    def _log(self, method_name: str, *args, **kwargs):
        """ç»Ÿä¸€çš„æ—¥å¿—è®°å½•æ–¹æ³•"""
        for logger in self.loggers:
            if hasattr(logger, method_name):
                log_method = getattr(logger, method_name)
                try:
                    log_method(*args, **kwargs)
                except Exception as e:
                    print(f"æ—¥å¿—è®°å½•é”™è¯¯ ({method_name}): {e}")

    def _load_checkpoint(self, checkpoint_path: str):
        """åŠ è½½æ£€æŸ¥ç‚¹"""
        state = self.model_manager.load(self.model, self.optimizer, checkpoint_path)
        if state:
            self.current_epoch = state['epoch'] + 1  # ä»ä¸‹ä¸€è½®å¼€å§‹
            self.best_metric = state.get('best_metric', self.best_metric)
            print(f"ä»epoch {state['epoch']}æ¢å¤è®­ç»ƒ")

    def _train_epoch(self) -> float:
        """è®­ç»ƒé˜¶æ®µ - åªè®¡ç®—æŸå¤±"""
        self.model.train()
        total_loss = 0.0
        loss_fn = self.config['loss_fn']

        for batch_idx, (data, target) in enumerate(self.train_loader):
            start_time = time.time()
            data, target = data.to(self.device), target.to(self.device)

            self.optimizer.zero_grad()
            output = self.model(data)
            loss = loss_fn(output, target)
            loss.backward()
            self.optimizer.step()

            total_loss += loss.item()
            use_time = time.time() - start_time

            # è®°å½•æ—¶é—´
            self._log('log_time', f"è®­ç»ƒbatch {batch_idx} è€—æ—¶: {use_time:.2f}s")

            # è®°å½•æŸå¤±
            self._log('log_loss', 'train', self.current_epoch, batch_idx, loss.item())

            if not self.trainning:
                break

        return total_loss / len(self.train_loader)

    def _validate(self) -> Dict[str, float]:
        """éªŒè¯é˜¶æ®µ - è®¡ç®—æ‰€æœ‰è¯„ä¼°æŒ‡æ ‡"""
        self.model.eval()
        all_outputs = []
        all_targets = []

        with torch.no_grad():
            for batch_idx, (data, target) in enumerate(self.val_loader):
                start_time = time.time()
                # åŒæ—¶ç§»åŠ¨dataå’Œtargetåˆ°è®¾å¤‡
                data, target = data.to(self.device), target.to(self.device)
                output = self.model(data)
                all_outputs.append(output.cpu())
                all_targets.append(target.cpu())

                use_time = time.time() - start_time

                # è®°å½•æ—¶é—´
                self._log('log_time', f"éªŒè¯batch {batch_idx} è€—æ—¶: {use_time:.2f}s")

                # è®°å½•éªŒè¯æŸå¤±ï¼ˆå¯é€‰ï¼‰
                val_loss = self.loss_fn(output, target).item()
                self._log('log_loss', 'val', self.current_epoch, batch_idx, val_loss)

        # åˆå¹¶è®¡ç®—è¯„ä¼°æŒ‡æ ‡
        combined_output = torch.cat(all_outputs, dim=0)
        combined_target = torch.cat(all_targets, dim=0)

        if self.metric_evaluator:
            val_metrics = self.metric_evaluator.evaluate(combined_output, combined_target)
            # è®°å½•è¯„ä¼°æŒ‡æ ‡
            self._log('log_metrics', self.current_epoch, val_metrics)
            return val_metrics
        return {}

    def start_train(self):
        """å¼€å§‹è®­ç»ƒ - æ·»åŠ æ—©åœæœºåˆ¶"""
        self.train_loader = self.config['train_loader']
        self.val_loader = self.config['val_loader']
        self.trainning = True

        for epoch in range(self.current_epoch, self.config['epochs'] + 1):
            self.current_epoch = epoch

            # è®°å½•epochå¼€å§‹æ—¶é—´
            epoch_start_time = time.time()

            # è®­ç»ƒé˜¶æ®µ
            train_loss = self._train_epoch()
            # éªŒè¯é˜¶æ®µ
            val_metrics = self._validate()

            # æ›´æ–°å­¦ä¹ ç‡
            self.scheduler.step(train_loss)

            # è®°å½•epochæ€»è€—æ—¶
            epoch_use_time = time.time() - epoch_start_time
            self._log('log_time', f"Epoch {epoch} æ€»è€—æ—¶: {epoch_use_time:.2f}s")
            # æ¨¡å‹ä¿å­˜å’Œæ—©åœæ£€æŸ¥
            if train_loss < self.best_metric:
                self.best_metric = train_loss
                self.early_stop_counter = 0
                self.model_manager.save(
                    self.model, self.optimizer, epoch,
                    'best_model.pth',
                    best_metric=self.best_metric,
                    val_metrics=val_metrics
                )
                self._log('log_time', f"ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹ (loss: {train_loss:.4f})")
            else:
                self.early_stop_counter += 1
                if self.early_stop_counter >= self.patience:
                    self._log('log_time', f"ğŸ›‘ æ—©åœè§¦å‘ï¼Œè¿ç»­{self.patience}ä¸ªepochæœªæ”¹å–„")
                    break
            # å®šæœŸä¿å­˜
            if epoch % 10 == 0:
                self.save()

            if not self.trainning:
                break

        self._log('log_time', "è®­ç»ƒå®Œæˆ!")

    def save(self):
        filename = f'checkpoint_epoch_{self.current_epoch}.pth'
        self.model_manager.save(self.model, self.optimizer, self.current_epoch, filename)
        msg = f'save model to {filename}'
        print(msg)
        return msg

    def stop(self, arg):
        self.save()
        self.trainning = False
        print("è®­ç»ƒåœæ­¢")
