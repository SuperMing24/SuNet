import nibabel as nib
import numpy as np
import torch
from PIL import Image
from utils.segutil import SegDataset, tongbu_trans
from scipy.ndimage import zoom

class MedicalDataProcessor:
    """åŒ»å­¦å›¾åƒæ•°æ®å¤„ç†å™¨ - ä¿æŒè·¨åˆ‡ç‰‡å¤„ç†"""

    @staticmethod
    def extract_multislice_data(volume, center_slice, num_slices=3):
        """
        æå–å¤šä¸ªç›¸é‚»åˆ‡ç‰‡ï¼Œç”¨äºè·¨åˆ‡ç‰‡ä¸Šä¸‹æ–‡

        å‚æ•°:
            volume: 3Dä½“ç§¯æ•°æ® [H, W, D]
            center_slice: ä¸­å¿ƒåˆ‡ç‰‡ç´¢å¼•
            num_slices: æå–çš„åˆ‡ç‰‡æ•°é‡ï¼ˆå¿…é¡»ä¸ºå¥‡æ•°ï¼‰

        è¿”å›:
            å¤šåˆ‡ç‰‡æ•°æ® [H, W, num_slices]
        """
        if num_slices % 2 == 0:
            raise ValueError("num_slices å¿…é¡»ä¸ºå¥‡æ•°ä»¥ä¿è¯å¯¹ç§°")

        half = num_slices // 2
        slices = []

        for i in range(-half, half + 1):
            slice_idx = max(0, min(center_slice + i, volume.shape[2] - 1))
            slices.append(volume[:, :, slice_idx])

        return np.stack(slices, axis=-1)  # [H, W, num_slices]

    @staticmethod
    def numpy_to_pil_compatible(array, is_mask=False):
        """
        å°†numpyæ•°ç»„è½¬æ¢ä¸ºPILå…¼å®¹çš„æ ¼å¼ï¼ŒåŒæ—¶ä¿æŒè·¨åˆ‡ç‰‡ä¿¡æ¯

        å‚æ•°:
            array: numpyæ•°ç»„ [H, W, C]
            is_mask: æ˜¯å¦ä¸ºæ©ç æ•°æ®

        è¿”å›:
            PILå›¾åƒå¯¹è±¡
        """
        # ç¡®ä¿æ•°æ®åœ¨0-255èŒƒå›´å†…
        if array.dtype != np.uint8:
            if is_mask:
                # å¯¹äºæ©ç ï¼Œç›´æ¥äºŒå€¼åŒ–
                array = (array > 0).astype(np.uint8) * 255
            else:
                # å¯¹äºå›¾åƒï¼Œè¿›è¡Œå½’ä¸€åŒ–åˆ°0-255
                array = (array - array.min()) / (array.max() - array.min() + 1e-8) * 255
                array = array.astype(np.uint8)

        # å¤„ç†å¤šé€šé“æƒ…å†µï¼ˆè·¨åˆ‡ç‰‡ï¼‰
        if array.shape[2] == 1:
            return Image.fromarray(array[:, :, 0], 'L')
        elif array.shape[2] == 3:
            return Image.fromarray(array, 'RGB')
        else:
            # å¦‚æœåˆ‡ç‰‡æ•°ä¸æ˜¯1æˆ–3ï¼Œå–å‰3ä¸ªé€šé“æˆ–è¿›è¡Œå…¶ä»–å¤„ç†
            # è¿™é‡Œå¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´
            if array.shape[2] > 3:
                array = array[:, :, :3]  # å–å‰3ä¸ªåˆ‡ç‰‡
            return Image.fromarray(array, 'RGB')

    @staticmethod
    def pil_to_medical_tensor(pil_image, original_dtype=np.float32):
        """
        å°†PILå›¾åƒè½¬æ¢å›åŒ»å­¦å›¾åƒæ ¼å¼çš„Tensor

        å‚æ•°:
            pil_image: PILå›¾åƒå¯¹è±¡
            original_dtype: åŸå§‹æ•°æ®ç±»å‹

        è¿”å›:
            PyTorch Tensor [C, H, W]
        """
            # ğŸ”§ å…³é”®ä¿®å¤ï¼šæ£€æŸ¥è¾“å…¥ç±»å‹
        if isinstance(pil_image, torch.Tensor):
            # å¦‚æœå·²ç»æ˜¯Tensorï¼Œç¡®ä¿ç»´åº¦é¡ºåºæ­£ç¡®
            if pil_image.dim() == 3:
                # [C, H, W] é¡ºåºï¼Œç›´æ¥è¿”å›
                return pil_image
            elif pil_image.dim() == 4:
                # [B, C, H, W] é¡ºåºï¼Œå»æ‰batchç»´åº¦
                return pil_image.squeeze(0)
            else:
                # å…¶ä»–æƒ…å†µï¼Œä¿æŒåŸæ ·
                return pil_image
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        array = np.array(pil_image)

        # è°ƒæ•´ç»´åº¦é¡ºåº
        if array.ndim == 2:  # ç°åº¦å›¾åƒ
            array = array[:, :, np.newaxis]  # [H, W] â†’ [H, W, 1]

        # è½¬æ¢å›åŸå§‹æ•°å€¼èŒƒå›´ï¼ˆè¿‘ä¼¼ï¼‰
        # æ³¨æ„ï¼šè¿™é‡Œä¼šæœ‰ç²¾åº¦æŸå¤±ï¼Œä½†ä¿æŒäº†è·¨åˆ‡ç‰‡ä¿¡æ¯
        if original_dtype == np.float32:
            array = array.astype(np.float32) / 255.0

        # ğŸ”§ å…³é”®ä¿®å¤ï¼šç¡®ä¿æ­£ç¡®çš„ç»´åº¦é¡ºåº [C, H, W]
        if array.shape[2] in [1, 3]:  # å•é€šé“æˆ–3é€šé“
            tensor = torch.from_numpy(array.transpose(2, 0, 1))  # [H, W, C] â†’ [C, H, W]
        else:
            # å…¶ä»–é€šé“æ•°ï¼Œä¿æŒåŸæ ·
            tensor = torch.from_numpy(array)

        return tensor

class Cat25Dataset(SegDataset):
    """ä¿®æ”¹åçš„Cat25Datasetï¼Œä¿æŒè·¨åˆ‡ç‰‡å¤„ç†å¹¶å…¼å®¹transforms"""

    def __init__(self, img_dir, mask_dir, transforms=[], check='none', num_slices=3):
        """
        å‚æ•°:
            num_slices: è·¨åˆ‡ç‰‡æ•°é‡ï¼Œé»˜è®¤ä¸º3ä¸ªåˆ‡ç‰‡
        """
        self.num_slices = num_slices
        self.processor = MedicalDataProcessor()
        super().__init__(img_dir, mask_dir, transforms, check)

    def _resolve_ids(self, img_dir, mask_dir, check):
        """é‡å†™æ–‡ä»¶è§£æï¼ŒåŠ è½½NIfTIæ•°æ®"""
        image_pairs = super()._resolve_ids(img_dir, mask_dir, check)
        self.load_datas = {}

        # é¢„åŠ è½½æ‰€æœ‰NIfTIæ–‡ä»¶ï¼Œä¿æŒåŸå§‹float32ç²¾åº¦
        for image_file, mask_file in image_pairs:
            self.load_datas[image_file] = nib.load(image_file).get_fdata().astype(np.float32)
            self.load_datas[mask_file] = nib.load(mask_file).get_fdata().astype(np.float32)

        id_pairs = []
        for image_file, mask_file in image_pairs:
            for layer in range(self.load_datas[image_file].shape[2]):
                id_pairs.append((image_file, mask_file, layer))
        return id_pairs

    def _load_datas(self, id):
        """é‡å†™æ•°æ®åŠ è½½ï¼Œä¿æŒè·¨åˆ‡ç‰‡å¤„ç†"""
        image_file, mask_file, layer = id
        image_data = self.load_datas[image_file]
        mask_data = self.load_datas[mask_file]

        # æå–å¤šä¸ªç›¸é‚»åˆ‡ç‰‡ç”¨äºä¸Šä¸‹æ–‡ä¿¡æ¯
        processed_images = self.processor.extract_multislice_data(
            image_data, layer, self.num_slices
        )

        # å¯¹æ¯ä¸ªåˆ‡ç‰‡çš„é€šé“è¿›è¡Œå½’ä¸€åŒ–
        means = processed_images.mean(axis=(0, 1))  # æ¯ä¸ªåˆ‡ç‰‡çš„å‡å€¼
        stds = processed_images.std(axis=(0, 1))    # æ¯ä¸ªåˆ‡ç‰‡çš„æ ‡å‡†å·®
        processed_images = (processed_images - means) / (stds + 1e-8)

        # æ©ç åªä½¿ç”¨ä¸­å¿ƒåˆ‡ç‰‡ï¼Œä½†ä¿æŒç›¸åŒçš„å¤„ç†æ¥å£
        processed_masks = mask_data[:, :, [layer]]  # [H, W, 1]
        processed_masks = (processed_masks > 0).astype(np.float32)

        # è½¬æ¢ä¸ºPILå…¼å®¹æ ¼å¼ä»¥æ”¯æŒtransforms
        image_pil = self.processor.numpy_to_pil_compatible(processed_images, is_mask=False)
        mask_pil = self.processor.numpy_to_pil_compatible(processed_masks, is_mask=True)

        return image_pil, mask_pil

    def __getitem__(self, idx):
        """é‡å†™getitemä»¥åœ¨è½¬æ¢åæ¢å¤åŒ»å­¦å›¾åƒæ ¼å¼"""
        id = self.image_mask_pairs[idx]
        image_pil, mask_pil = self._load_datas(id)

        # åº”ç”¨æ ‡å‡†çš„torchvision transforms
        for transform, tb in self.transforms:
            if tb:
                image_pil, mask_pil = tongbu_trans(transform, image_pil, mask_pil)
            else:
                image_pil = transform(image_pil)
                mask_pil = transform(mask_pil)

        # è½¬æ¢å›åŒ»å­¦å›¾åƒæ ¼å¼çš„Tensor
        image_tensor = self.processor.pil_to_medical_tensor(image_pil, np.float32)
        mask_tensor = self.processor.pil_to_medical_tensor(mask_pil, np.float32)

        return image_tensor, mask_tensor
